{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MINST code.ipynb","provenance":[],"collapsed_sections":["MfKu14Dg8oYG","9AqukDivTlI5","JqJ8jVAjYRIg","S2hRb_gTcf5E"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MfKu14Dg8oYG"},"source":["# 1. Keeping the same parameters\n","\n","Image size is 1x28x28\n","\n","      First Convolution : 1x28x28 --> (padding) 1x30x30 --> (kernel & filters) 32x28x28\n","      Second Convolution : 32x28x28 --> (padding) 32x30x30 --> (kernel & filters) 64x28x28\n","      After max pooling: 64x14x14\n","      Third Convolution : 64x14x14 --> (padding) 64x16x16 --> (kernel & filters) 128x14x14\n","      Forth Convolution : 128x14x14 --> (padding) 128x16x16 --> (kernel & filters) 256x14x14\n","      After max pooling: 256x7x7\n","      Fifth Convolution : 256x7x7 --> (kernel & filters) 512x5x5\n","      sixth Convolution : 512x5x5 --> (kernel & filters) 1024x3x3\n","      Saventh Convolution : 1024x3x3 --> (kernel & filters) 10x1x1\n","\n","Using this parameters \n","\n","      Train loss = 1.99\n","      Average Test loss = 1.96 \n","\n"]},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","executionInfo":{"status":"ok","timestamp":1631081961920,"user_tz":-330,"elapsed":410,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from tqdm import tqdm\n","from torchsummary import summary"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","executionInfo":{"status":"ok","timestamp":1631081961921,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["class Net(nn.Module): # image siE in mnist is 1x28x28\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  \n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv5 = nn.Conv2d(256, 512, 3)\n","        self.conv6 = nn.Conv2d(512, 1024, 3,  padding=1)\n","        self.conv7 = nn.Conv2d(1024, 10, 3)\n","        self.conv8 = nn.Conv2d(10, 10, 2)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) \n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = F.relu(self.conv8(F.relu(self.conv7(x))))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631081964639,"user_tz":-330,"elapsed":2031,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}},"outputId":"563561b8-b592-4bfa-8ae5-dfaf7a40aa39"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 28, 28]             320\n","            Conv2d-2           [-1, 64, 26, 26]          18,496\n","         MaxPool2d-3           [-1, 64, 13, 13]               0\n","            Conv2d-4          [-1, 128, 13, 13]          73,856\n","            Conv2d-5          [-1, 256, 13, 13]         295,168\n","         MaxPool2d-6            [-1, 256, 6, 6]               0\n","            Conv2d-7            [-1, 512, 4, 4]       1,180,160\n","            Conv2d-8           [-1, 1024, 4, 4]       4,719,616\n","            Conv2d-9             [-1, 10, 2, 2]          92,170\n","           Conv2d-10             [-1, 10, 1, 1]             410\n","================================================================\n","Total params: 6,380,196\n","Trainable params: 6,380,196\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.36\n","Params size (MB): 24.34\n","Estimated Total Size (MB): 25.70\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"]}]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631081964639,"user_tz":-330,"elapsed":16,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}},"outputId":"1368b9f3-5215-47cc-b1a1-888ca048974a"},"source":["torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"]}]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","executionInfo":{"status":"ok","timestamp":1631081964640,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631082053317,"user_tz":-330,"elapsed":88689,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}},"outputId":"95c4012f-1b89-4300-de0c-5251bc8b1bdb"},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 2):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=1.772858738899231 batch_id=468: 100%|██████████| 469/469 [01:24<00:00,  5.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 1.8408, Accuracy: 2105/10000 (21%)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"9AqukDivTlI5"},"source":["# 2. Changing the parameters ( Decreasing the size of filters)\n","\n","Image size is 1x28x28\n","\n","      First Convolution : 1x28x28 --> (padding) 1x30x30 --> (kernel & filters) 1024x28x28\n","      Second Convolution : 1024x28x28 --> (padding) 1024x30x30 --> (kernel & filters) 512x28x28\n","      After max pooling: 512x14x14\n","      Third Convolution : 512x14x14 --> (padding) 512x16x16 --> (kernel & filters) 256x14x14\n","      Forth Convolution : 256x14x14 --> (padding) 256x16x16 --> (kernel & filters) 128x14x14\n","      After max pooling: 128x7x7\n","      Fifth Convolution : 128x7x7 --> (kernel & filters) 64x5x5\n","      sixth Convolution : 64x5x5 --> (kernel & filters) 32x3x3\n","      Saventh Convolution : 32x3x3 --> (kernel & filters) 10x1x1\n","\n","Using this parameters \n","\n","      Train loss = 0.37\n","      Average Test loss = 0.53\n","\n","### By using this method we can see that there is a decrease in the loss."]},{"cell_type":"code","metadata":{"id":"Z42-oeFzTpxQ","executionInfo":{"status":"aborted","timestamp":1631080563162,"user_tz":-330,"elapsed":21,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["class Net2(nn.Module): # image siE in mnist is 1x28x28\n","    def __init__(self):\n","        super(Net2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 1024, 3, padding=1)  \n","        self.conv2 = nn.Conv2d(1024, 512, 3, padding=1)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(512, 256, 3, padding=1)\n","        self.conv4 = nn.Conv2d(256, 128, 3, padding=1)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv5 = nn.Conv2d(128, 64, 3)\n","        self.conv6 = nn.Conv2d(64, 32, 3)\n","        self.conv7 = nn.Conv2d(32, 10, 3)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) \n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = F.relu(self.conv7(x))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3V8QiIgUQJz","executionInfo":{"status":"aborted","timestamp":1631080563163,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["use_cuda = torch.cuda.is_available()\n","device2 = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model2 = Net2().to(device2)\n","summary(model2, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHBd6WhJUT0T","executionInfo":{"status":"aborted","timestamp":1631080563163,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["model2 = Net2().to(device2)\n","optimizer = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 2):\n","    train(model2, device2, train_loader, optimizer, epoch)\n","    test(model2, device2, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqJ8jVAjYRIg"},"source":["# 3. Decreasing filters without padding\n","\n","Image size is 1x28x28\n","\n","      First Convolution : 1x28x28 --> (kernel & filters) 512x26x26\n","      Second Convolution : 512x26x26 --> (kernel & filters) 256x24x24\n","      After max pooling: 256x12x12\n","      Third Convolution : 256x12x12 --> (kernel & filters) 128x10x10\n","      Forth Convolution : 128x10x10 --> ((kernel & filters) 64x8x8\n","      After max pooling: 64x4x4\n","      Fifth Convolution : 64x4x4 --> (kernel & filters) 32x2x2\n","      sixth Convolution : 32x2x2 --> (kernel & filters) 10x1x1\n","\n","Using this parameters \n","\n","      Train loss = 1.073\n","      Average Test loss = 1.176\n","\n","### By removing padding, loss is increasing, so we will use padding\n","\n"]},{"cell_type":"code","metadata":{"id":"jVFeJsg9VueP","executionInfo":{"status":"aborted","timestamp":1631080563163,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["class Net3(nn.Module): # image siE in mnist is 1x28x28\n","    def __init__(self):\n","        super(Net3, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 512, 3, padding='valid')  \n","        self.conv2 = nn.Conv2d(512, 256, 3, padding='valid')\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(256, 128, 3, padding='valid')\n","        self.conv4 = nn.Conv2d(128, 64, 3, padding='valid')\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv5 = nn.Conv2d(64, 32, 3)\n","        self.conv6 = nn.Conv2d(32, 10, 2)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) \n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jglCAkWPZILR","executionInfo":{"status":"aborted","timestamp":1631080563164,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["use_cuda = torch.cuda.is_available()\n","device3 = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model3 = Net3().to(device3)\n","summary(model3, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDduLdpAZOtd","executionInfo":{"status":"aborted","timestamp":1631080563168,"user_tz":-330,"elapsed":27,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["model3 = Net3().to(device3)\n","optimizer = optim.SGD(model3.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 2):\n","    train(model3, device3, train_loader, optimizer, epoch)\n","    test(model3, device3, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S2hRb_gTcf5E"},"source":["# 4. Removing max pooling and kernel size = 5\n","\n","Image size is 1x28x28\n","\n","      First Convolution : 1x28x28 --> (padding) 1x30x30 --> (kernel & filters) 1024x28x28\n","      Second Convolution : 1024x28x28 --> (padding) 1024x30x30 --> (kernel & filters) 512x28x28\n","      Third Convolution : 512x28x28--> (padding) 512x30x30 --> (kernel & filters) 256x28x28\n","      Forth Convolution : 256x28x28 --> (padding) 256x30x30 --> (kernel & filters) 128x28x28\n","      Fifth Convolution : 128x28x28 --> (kernel & filters) 64x24x24\n","      sixth Convolution : 64x24x24 --> (kernel & filters) 32x20x20\n","      Saventh Convolution : 32x20x20 --> (kernel & filters) 10x16x16\n","      Eight Convolution : 10x16x16 --> (kernel & filters) 10x12x12\n","      Ninth Convolution : 10x12x12 --> (kernel & filters) 10x8x8\n","      Tenth Convolution : 10x8x8 --> (kernel & filters) 10x4x4\n","      Tenth Convolution : 10x4x4 --> (kernel & filters) 10x1x1\n","\n","Using this parameters \n","\n","      Train loss = 2.30\n","      Average Test loss = 2.30\n","\n","### By removing pooling loss is incresing"]},{"cell_type":"code","metadata":{"id":"A30s58l3arqw","executionInfo":{"status":"aborted","timestamp":1631080563170,"user_tz":-330,"elapsed":29,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["class Net4(nn.Module): # image siE in mnist is 1x28x28\n","    def __init__(self):\n","        super(Net4, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 1024, 5, padding=2)  \n","        self.conv2 = nn.Conv2d(1024, 512, 5, padding=2)\n","        self.conv3 = nn.Conv2d(512, 256, 5, padding=2)\n","        self.conv4 = nn.Conv2d(256, 128, 5, padding=2)\n","        self.conv5 = nn.Conv2d(128, 64, 5)\n","        self.conv6 = nn.Conv2d(64, 32, 5)\n","        self.conv7 = nn.Conv2d(32, 10, 5)\n","        self.conv8 = nn.Conv2d(10, 10, 5)\n","        self.conv9 = nn.Conv2d(10, 10, 5)\n","        self.conv10 = nn.Conv2d(10, 10, 5)\n","        self.conv11 = nn.Conv2d(10, 10, 4)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv2(F.relu(self.conv1(x)))) \n","        x = F.relu(self.conv4(F.relu(self.conv3(x))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = F.relu(self.conv8(F.relu(self.conv7(x))))\n","        x = F.relu(self.conv10(F.relu(self.conv9(x))))\n","        x = F.relu(self.conv11(x))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dbwXDKldE2l","executionInfo":{"status":"aborted","timestamp":1631080563171,"user_tz":-330,"elapsed":29,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["use_cuda = torch.cuda.is_available()\n","device4 = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model4 = Net4().to(device4)\n","summary(model4, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rt6CNzS6dJOe","executionInfo":{"status":"aborted","timestamp":1631080563172,"user_tz":-330,"elapsed":30,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":["model4 = Net4().to(device4)\n","optimizer = optim.SGD(model4.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 2):\n","    train(model4, device3, train_loader, optimizer, epoch)\n","    test(model4, device3, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3R5680c3dyms","executionInfo":{"status":"aborted","timestamp":1631080563172,"user_tz":-330,"elapsed":30,"user":{"displayName":"Rahul Kadam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDEYPwNput4fRqhrrZkHXLlLlM9udbZ9NQdB2JIA=s64","userId":"05509169337695293545"}}},"source":[""],"execution_count":null,"outputs":[]}]}